{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/Agentic-AI-with-Python/blob/main/notebooks/Foundations%20of%20Agentic%20AI/Creating_and_Using_Prompt_Templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlg-QQc03gnw"
      },
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://ionnova.com/img/ionnova_logo_name_2.png\" width=\"120px\"></td>\n",
        "    <td><h1>Creating and Using Prompt Templates</h1></td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XjnO-qljyTRj",
        "outputId": "edf7b9a9-ca7e-4ff0-d90b-ae49cd8328b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8NZ2_4NqzCx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7d0c54-1bb1-47b9-f152-cba55bff2f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Agent with Input: 'What is the capital of Japan?' ---\n",
            "\n",
            "Web Search Result:\n",
            "Thought: I need to use the get_product_price tool to retrieve the price and shipping details for the specific Amazon product mentioned by the user.\n",
            "Action: get_product_price\n",
            "Action Input: {__arg1: \"B07VGRJDFY\"}\n",
            "Observation: tool_result\n",
            "--- Running Agent with Input: 'I need the price of a Fire TV Stick.' ---\n",
            "\n",
            "Price Tool Result:\n",
            "The user is asking for the price and shipping details of a specific Amazon product. To provide this information, I will use the get_product_price tool.\n",
            "\n",
            "Thought: I will use the get_product_price tool to retrieve the price and shipping details of the Amazon product.\n",
            "Action: get_product_price\n",
            "Action Input: {__arg1: \"Amazon product ASIN or URL\"}\n",
            "Observation: tool_result\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load API keys from a .env file for secure credential management.\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the Large Language Model (LLM) for the agent's brain.\n",
        "# Using gpt-3.5-turbo with temperature=0 for deterministic, reliable tool-use reasoning.\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# --- Tool Definitions ---\n",
        "\n",
        "def get_product_price(product_name: str) -> str:\n",
        "    \"\"\"Simulates fetching price data for a product.\"\"\"\n",
        "    return f\"Simulated price for '{product_name}': $19.99 with Prime shipping.\"\n",
        "\n",
        "# Tool description: This text is read by the LLM to decide if the tool is relevant.\n",
        "# Specificity is key to proper tool selection.\n",
        "price_tool = Tool(\n",
        "    name=\"get_product_price\",\n",
        "    func=get_product_price,\n",
        "    description=\"Strictly for retrieving the simulated price and shipping details for a specific Amazon product.\"\n",
        ")\n",
        "\n",
        "\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Simulates a web search for general knowledge.\"\"\"\n",
        "    return f\"Simulated search result for: {query}\"\n",
        "\n",
        "# Tool description: Detailed description helps the LLM choose this for generic queries.\n",
        "search_tool = Tool(\n",
        "    name=\"web_search\",\n",
        "    func=web_search,\n",
        "    description=\"This tool is essential for finding current information, recent news, and general facts.\"\n",
        ")\n",
        "\n",
        "# --- Prompt Template Definition ---\n",
        "\n",
        "# Define the structured instructions (the system prompt) for the agent's thinking process (ReAct pattern).\n",
        "template = \"\"\"\n",
        "You are a helpful and meticulous assistant, skilled at using your tools to answer user queries.\n",
        "\n",
        "Your overall objective is: {task}\n",
        "\n",
        "You must strictly follow the Thought/Action/Observation format.\n",
        "\n",
        "Use the following format:\n",
        "Thought: I need to determine which tool is best suited to answer the user's question, or if I should answer directly.\n",
        "Action: tool_name (or 'Final Answer' if answering directly)\n",
        "Action Input: input_for_tool (or the final text answer)\n",
        "Observation: tool_result (or none)\n",
        "\"\"\"\n",
        "\n",
        "# Create the PromptTemplate object.\n",
        "custom_system_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"task\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# --- Agent Creation ---\n",
        "\n",
        "# Define the specific instruction to inject into the template's 'task' variable.\n",
        "agent_task_instruction = \"Your primary goal is to use the provided tools (get_product_price and web_search) to fully address the user's question by performing one or more tool calls.\"\n",
        "\n",
        "# 1. Format the PromptTemplate into a single string. This is the fix:\n",
        "#    The `system_prompt` argument in `create_agent` requires a string, not the PromptTemplate object itself.\n",
        "final_system_prompt_string = custom_system_prompt_template.format(\n",
        "    task=agent_task_instruction\n",
        ")\n",
        "\n",
        "# 2. Create the Agent: combines the LLM, the list of tools, and the final system prompt string.\n",
        "agent = create_agent(\n",
        "    tools=[price_tool, search_tool],\n",
        "    model=llm,\n",
        "    system_prompt=final_system_prompt_string\n",
        ")\n",
        "\n",
        "\n",
        "# --- Agent Execution Function ---\n",
        "\n",
        "def run_agent(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Invokes the agent with a user query and returns the final textual response.\n",
        "    The final answer is extracted from the agent's response object.\n",
        "    \"\"\"\n",
        "    print(f\"--- Running Agent with Input: '{user_input}' ---\")\n",
        "\n",
        "    # Invokes the agent chain.\n",
        "    response = agent.invoke({\n",
        "        \"input\": user_input\n",
        "    })\n",
        "\n",
        "    # Extracts the final answer text from the agent's response object.\n",
        "    return response[\"messages\"][-1].content\n",
        "\n",
        "# --- Example Runs to Test Both Tools ---\n",
        "\n",
        "# Test 1: Query that should trigger the 'web_search' tool.\n",
        "web_search_result = run_agent(\"What is the capital of Japan?\")\n",
        "print(f\"\\nWeb Search Result:\\n{web_search_result}\")\n",
        "\n",
        "# Test 2: Query that should trigger the 'get_product_price' tool.\n",
        "price_result = run_agent(\"I need the price of a Fire TV Stick.\")\n",
        "print(f\"\\nPrice Tool Result:\\n{price_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEdnwLF-7GNl"
      },
      "source": [
        "### Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u6x5j6W17DNb",
        "outputId": "f42bfd3a-8aa7-4e27-9f7d-03b38b57487f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Agent with Input: 'What's the price of a wireless mouse?' ---\n",
            "The user is asking for the price and shipping details of a specific Amazon product. To provide this information, I will use the get_product_price tool.\n",
            "\n",
            "Thought: I will use the get_product_price tool to retrieve the price and shipping details of the Amazon product.\n",
            "Action: get_product_price\n",
            "Action Input: {__arg1: \"Amazon product ASIN or URL\"}\n",
            "Observation: tool_result\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"What's the price of a wireless mouse?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0CzV2j1O7S5G",
        "outputId": "bfe5f8f6-b37a-472c-90fd-869ab7ee64f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Agent with Input: 'Search for the latest developments in AI regulation.' ---\n",
            "Final Answer: The simulated price for the Amazon Echo Dot is $19.99 with Prime shipping.\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"Search for the latest developments in AI regulation.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XOVKmnfN7VES",
        "outputId": "d57e0aa2-192d-46e2-f11b-eb4c8702b663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Agent with Input: 'What's the price of a wireless mouse and also search about AI news?' ---\n",
            "The user is asking for the price and shipping details of a specific Amazon product. I will use the get_product_price tool to retrieve this information.\n",
            "\n",
            "Action: get_product_price\n",
            "Action Input: {__arg1: \"Amazon product ASIN or URL\"}\n",
            "Observation: tool_result\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"What's the price of a wireless mouse and also search about AI news?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}